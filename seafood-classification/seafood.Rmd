---
title: "Data Science Practicum Report : Seafood Appearances on Historical Menus"
author: 
  - Alan Nurcahyo^[American University; an4234a@student.american.edu]
date: "2020-12-01"
abstract: "The New York Public Library has compiled a database of menu items dating back to the 1840s. The goal of this project is to develop an automated approach for identifying and categorizing seafood dishes  The model that we use to predict unlabeled dataset is Random forest with ntree= 500 and m=500. The model has 98.21 percent accuracy, 98.38 percent sensitivity, and 97.14 specificity on test set. we find that Oyster was a popular food for almost 100 years, Lobster isn’t popular seafood dishes until mid 19th century, and Shrimp steadily increased in popularity."
output: pdf_document
---
# 1. Project Overview
## 1.1 Project Name
Seafood Appearances on Historical Menus

## 1.2 Client Information
Jessica Gephart, Seafood Globalization Lab. Email: jgephart@american.edu

## 1.3 Project start-end
Monday, August 24, 2020 - Friday, December 4, 2020

## 1.4 Project description and Prerequisities
The New York Public Library has compiled a database of menu items dating back to the 1840s. The goal of this project is to develop an automated approach for identifying and categorizing seafood dishes. The resulting categorization will be used to understand the change in seafood diversity and sourcing over time within this menu collection. Seafood Globalization Lab has labeled 38,491 dishes from the New York Public Library database as seafood and nonseafood, which might be used as training and testing datasets for machine learning techniques.

Student need to understand basic R and able to implement a machine learning method.

## 1.5 Student Information
Alan Nurcahyo, Graduate Student in Master Of Data Science Program, American University.

## 1.6 Student's Objective
The student is required to build off an initial training dataset and apply machine learning techniques to identify and categorize menu items into seafood or nonseafood dishes. The student will use either the labeled dataset for analysis. The result is a machine learning model capable of identifying and classifying dishes into seafood dishes and nonseafood dishes from New York Public Library database. The student is expected to present and validate different models using general classifier methods, including (but not limited to) Logistic Regression, Support Vector Machine, K-nearest neighbour etc. The choosen model is expected to be robust, capable of predicting new observations when the database is updated. All work will be written in R.

## 1.7 Student's Task
1. Preprocessing data for training and testing data, using a labeled dataset provided by the client.
2. Analyze the power of a sample from the labeled dataset.
3. Apply machine learning algorithm for identifying and categorizing menu items.
4. Create a machine learning model from the algorithm.
5. Tune model and validate results using test dataset.
6. Summarize and visualize findings.
7. Create a report based on findings.


# 2 NYPL Whats on the menu? datasets

The New York Public Library’s menu collection, housed in the Rare Book Division, originated 
through the energetic efforts of Miss Frank E. Buttolph (1850-1924), who, in 1900, began to 
collect menus on the Library's behalf. The collection has continued to grow through additional 
gifts of graphic, gastronomic, topical, or sociological interest, especially but not exclusively 
New York-related. The collection now contains approximately 45,000 menus dating from the 1840s 
to the present, about quarter of which have so far been digitized and made available in the 
NYPL Digital Gallery.

New York Public Library’s What’s on the Menu? project transcribes menu data using crowd-sourced
system. Volunteers joins the project and transcribe menu from scanned or photographed menu from 
the collection. The trancibing process is still continuing and the data were updated regularly. 
Therefore, it is possible that we will have more dish from older years than later years.

## 2.1 Load and review dataset
There are 423165 obs and 10 column in dataset.   
[1] "id": Unique Id for dish  
[2] "name": Name of dish  
[3] "description":   
[4] "menus_appeared": indicate how many menu list the dish in it  
[5] "times_appeared": indicate how many times dish appeared during first time 
appeared and last time appeared  
[6] "first_appeared": indicate year in which the dish first time seen  
[7] "last_appeared": indicate year in which the dish last time seen  
[8] "lowest_price": indicate the lowest price of dish ever recorded  
[9] "highest_price": indicate the highest price of dish ever recorded  
[10] "seafood_yn": indicate whether the dish is seafood (coded 1) or not a 
seafood (coded 0). NA indicate that the dish are not labeled.  
There are 3,492 observation that are labeled as seafood dishes and 25,182 labeled
as non-seafood dishes.  

```{r message=FALSE, echo=FALSE, warning = FALSE, results=FALSE}
library(tidyverse) #data wrangling
library(googleLanguageR) # translate

#load dataset
df <- read_csv("/Users/alannurcahyo/Documents/Documents/AU/fall2020/DATA/Seafood_Dishes.csv")

## column names
names(df)
##check label
dim(df)
unique(df$seafood_yn)
table(df$seafood_yn)
```
## 2.2 Sample evaluation
### 2.2.1 Distribution of labeled and non labeled by Year
Most of observtions dated from 1900's to 1920's, this happen due to the fact that the New York 
Public Library’s menu collection is started by Miss Frank E. Buttolph (1850-1924), who, in 1900, 
began to collect menus on the Library's behalf. Miss Buttolph added more than 25,000 menus to 
the collection, before leaving the Library in 1924. 

The histogram shows that the data lacks of observation from later year (after 1907). 
From total of 246,640 observations after 1907, only 58 of them are labeled.


```{r message=FALSE, echo=FALSE, warning = FALSE, results=FALSE}
####### Histogram for evaluation ##########
#Histogram of first time the menu appeared
# It appears that the labeled data lack of observation from later year
df %>%
  filter(first_appeared != 0,
         first_appeared != 1,
         first_appeared != 2928) %>%
  mutate( labeled = !is.na(seafood_yn)) %>%
  ggplot(aes(first_appeared, fill = labeled)) + 
  geom_histogram(binwidth = 10)+ theme_bw() +
  labs(title = "Data Distribution by First Appeared")

#Histogram of last time the menu appeared
# It appears that the labeled data has a sufficient range of observation
df %>%
  filter(last_appeared != 0,
         last_appeared != 1,
         last_appeared != 2928) %>%
  mutate( labeled = !is.na(seafood_yn)) %>%
  ggplot(aes(last_appeared, fill = labeled)) + 
  geom_histogram(binwidth = 10) + theme_bw() +
  labs(title = "Data Distribution by Last Appeared")

# comparison between labeled and unlabeled data by first appeared
# It appears that labeled data lack of observation after 1908 
count.first.appeared <- df %>%
  filter(first_appeared != 0,
         first_appeared != 1,
         first_appeared != 2928) %>%
  mutate( labeled = !is.na(seafood_yn)) %>%
  group_by(first_appeared, labeled) %>%
  count() %>%
  spread(labeled, n)
# number of observation after 1097
sum(count.first.appeared$`FALSE`[count.first.appeared$first_appeared>1907])

# number of labeled observation after 1097
sum(count.first.appeared$`TRUE`[count.first.appeared$first_appeared>1907], na.rm = TRUE)
```

We need to generate new sample so that dataset has a vocabulary from later years. To do that, 
we take one percent of oberservation after 1908 to be labeled. To make sure we have good additional
sample we take # observation based on it's proportion to dataset. Therefore, for example, if we 
have more dishes in 1988 than 1990, we take more sample from 1988 than 1990. This approach also 
making sure that we have at least one sample from all years. We have 2396 new observations to be 
labeled in the next step.

Finally, we label it 1 for seafood or 0 for non-seafood, then we bind new labeled sample to dataset.
```{r eval=FALSE, echo=FALSE}
####### Generate new sample ##########

# let's take one percent of oberservation after 1908 to be labeled and round it
# per year we need following observation
n_new_sample <- count.first.appeared %>%
  mutate(n_sample = round(`FALSE`/100,0)) %>%
  select(first_appeared,n_sample) %>%
  filter(first_appeared >1907,
         n_sample >0)

# we take n number of observation from unlabeled dataset by following the number 
# we need on n_new_sample$n_sample
new_sample <- vector(mode = "list", length = nrow(n_new_sample))
for (i in seq_along(new_sample)) {
  new_sample[[i]] <- df.unlabeled %>%
    filter(first_appeared == n_new_sample$first_appeared[[i]]) %>%
    sample_n(n_new_sample$n_sample[[i]])
}
new_sample <- do.call(rbind, new_sample)

# write it to csv
write_csv(new_sample,"new_sample.csv")
############ label it manually, then load the labeled new sample into R ####
new_sample_labeled <- read_csv("new_sample_labeled.csv")
dim(new_sample_labeled)
new_sample_labeled <- new_sample_labeled %>%
  filter(seafood_yn %in% c(0,1))

df <- df %>%
  anti_join(new_sample_labeled, by = "id")
df <- rbind(df, new_sample_labeled)
```

### 2.2.2 Translating dish name and evaluating data vocabulary

Name variable in the dataset is written in namy languages, including English, Germany,
and French. This difference in language used causes several problems. firstly, it is 
difficult for cleaning procedure such as removing stop words and stemming. Secondly, 
the same dish will be seen as different dish is it'swritten in other language. 
Therefore, we will translate name variable in dataset using Google Translate API.

Using Google API, we make loop function that translate dish name one by one and save 
it into a new object. Next, we use 'cbind' to merge it with dataset as new variable 
translatedText.

```{r eval = FALSE, echo=FALSE}
###################### use google API #########################
## the output file is saved in .csv because it is costly and time consuming to run it everytime
gl_auth("seafood-translation-f329aa685c7f.json")
df.name.translate <- vector(mode = "list", length = nrow(df))

for (i in seq_along(df.name.translate)) {
     df.name.translate[[i]] <- gl_translate(df$name[i], target = "en")
}

df.name.translate.bind <- do.call(rbind, df.name.translate)
df.name.translate.bind <- df.name.translate.bind %>%
  distinct()
write_csv(df.name.translate.bind, "translationgoogleall.csv")
df <- left_join(df, df.name.translate.bind)
```

Once we have all name in english, we can evaluate whether our our train sample has a proper 
vocabulary compared to the rest of dataset (unlabeled). 

To do that, first we separate labeled and unlabeled dataset. Then we make train and test 
from labeled dataset. We will do this process again after we add more observation to enrich 
vocabulary in our dataset.

```{r eval = FALSE, echo=FALSE}
unlabeled <- df %>%
  filter(is.na(seafood_yn))
labeled <- df %>%
  filter(!is.na(seafood_yn))
nrow(labeled) + nrow(unlabeled) == nrow(df)

###### create training and test with the same prob #######

#create index of stratified 80:20 split that maintain proportion of label.
index <- caret::createDataPartition(labeled$seafood_yn, times = 1,
                                    p = 0.8, list= FALSE) 

# train and test
train <- labeled[index,]
test <- labeled[-index,]

````

Next, we will create document frequency matrix from datasets so we can count each unique 
number of words in unlabeled dataset, dummy train dataset, and dummy test dataset.
```{r eval = FALSE, echo=FALSE}
#################### add vocabulary ##############
#create a corpus for unlabeled dataset
corpus <- corpus(unlabeled$translatedText) 

#create document frequency matrix with verb
dfm.unlabeled <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)


############ create a corpus for train  dataset #######
#create a corpus for unlabeled dataset
corpus <- corpus(train$translatedText) 

#create document frequency matrix with verb
dfm.train <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)


############ create a corpus for test  dataset #######
corpus <- corpus(test$translatedText) 

#create document frequency matrix with verb
dfm.test <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)
```

Once we had all three document frequency, we make a table that contain words count from each matrix
```{r eval = FALSE, echo = FALSE}
######### table that contain all word count in unlabeled ########
dfm.unlabeled.trimmed <- dfm_trim(dfm.unlabeled, min_docfreq = 15, verbose = TRUE)
dim(dfm.unlabeled.trimmed)
count.unlabeled <- apply(dfm.unlabeled.trimmed[1:100000,], 2, sum)
count.unlabeled2 <- apply(dfm.unlabeled.trimmed[100001:200000,], 2, sum)
count.unlabeled3 <- apply(dfm.unlabeled.trimmed[200001:300000,], 2, sum)
count.unlabeled4 <- apply(dfm.unlabeled.trimmed[300001:392095,], 2, sum)
count.unlabeled <- count.unlabeled+count.unlabeled2+count.unlabeled3+count.unlabeled4
count.unlabeled <- data.frame(name = names(count.unlabeled),
           freq = count.unlabeled)

######### table that contain all word count in dummy train ########
count.train <- apply(dfm.train, 2, sum)
count.train <- data.frame(name = names(count.train),
           freq = count.train)
######### table that contain all word count in dummy test ########
count.test <- apply(dfm.test,2,sum)
count.test <- data.frame(name = names(count.test),
           freq = count.test)
```

There might be too much data to evaluate. To make it feasible to add more sample we 
decided to choose 10,000 unique words that are most frequently appear. Then, we join 
top term from three count table that we had before. The results is a table of most 
frequent data that are not available in train and/or test dataset.
```{r eval = FALSE, echo=FALSE}
## top words
topterm.train <- count.train %>%
  arrange(desc(freq)) %>%
  slice(1:10000)

topterm.test <- count.test %>%
  arrange(desc(freq)) %>%
  slice(1:1000)

topterm.unlabeled <- count.unlabeled %>%
  arrange(desc(freq)) %>%
  slice(1:3000)

nothing.on.labeled <- topterm.unlabeled %>%
  left_join(topterm.train, by = "name") %>%
  left_join(topterm.test, by = "name") %>%
  filter(is.na(freq.y) & is.na(freq))
```

Based on table above, we decide to take 760 observations of words that aren't 
available in labeled dataset. 
```{r eval = FALSE, echo=FALSE}
nothing.on.labeled.smp <- nothing.on.labeled %>%
  mutate(freq.x = round(freq.x/100)+1)

sampleoct22 <- vector(mode = "list", length = nrow(nothing.on.labeled))
for (i in seq_along(sampleoct22)) {
  sampleoct22[[i]] <- df.unlabeled %>%
    filter(str_detect(translatedText,nothing.on.labeled$name[i])) %>%
    select(id, first_appeared) %>%
    arrange(desc(first_appeared)) %>%
    slice(1:nothing.on.labeled.smp$freq.x[[i]]) %>% ## take number of dish from latest dish 
                                                    ## (we low on new name dish)
    select(id)
}

sampleoct22 <- do.call(rbind, sampleoct22)
sampleoct22 <- unique(sampleoct22)
sampleoct22.vector <- sampleoct22$id

## add more label for pattern that are not available in training (see steps on appendix)
## our pattern
new.labeled.22oct <- df.unlabeled %>%
  filter(id %in% sampleoct22.vector)
write.csv(new.labeled.22oct, "newlabeled22oct.csv")
```

Then, we labele it manually. It worth to mention that even though we already translate
dish name to english, one dish name are remain unidentifiable whether it is a seafood 
or non seafood. We decided to leave it NA.
```{r eval = FALSE, echo=FALSE}
newlabeled22oct <- read_csv("newlabeled22oct.csv")
newlabeled22oct <- newlabeled22oct[,-1] 
which(is.na(newlabeled22oct$seafood_yn))
newlabeled22oct <- newlabeled22oct[-598,] 
```

At last, we add our new sample to our labeled dataset. Then we remove it from unlabeled
dataset. Finally we bind them together in df.all that contain all dataset.
```{r eval = FALSE, echo=FALSE}
##join it to labeled
labeled <- rbind(labeled, newlabeled22oct)

## remove it from unlabeled
unlabeled <- unlabeled %>%
  anti_join(newlabeled22oct, by = "id")

## join it to make one single datasets
df.all <- rbind(unlabeled, labeled)

## check
nrow(df.all) == nrow(df)

## save 
write_csv(df.all, file = "dfalltranslated.csv")
write_csv(labeled, file = "dflabeledtranslated.csv")
write_csv(unlabeled, file = "dfunlabeledtranslated.csv")
```

It worth to mention that There are some human error in labeled dataset, especially when 
dish name is not in english. Therefore, we still continue to evaluate seafood_yn variable 
in labeled dataset manually. Our final labeled dataset after final evaluation is dflabeledtranslated_edited.csv.

```{r message=FALSE, echo=FALSE}
library(tidyverse) ## for wrangling and tidying data
library(ROSE) ## to genereate undersample 
library(udpipe) ## to annotate text
library(caret) ## evaluation, detailed confusion matrix
library(quanteda) ## preprocessing text dosument
library(doSNOW) #run model to run in each core
library(irlba) #perform single value decomposition
library(class) #perform KNN
library(gganimate) ## animate
library(broom) ## tidy output of summary
library(tree) ## perform desicion tree
library(e1071) ## perform svm
library(randomForest) ## perform random forest
library(gganimate) ## graphic animate
```

# Data Preprocessing
## Overview on labeled dataset
A labeled dataset consist of 31,829 obs and 11 variables.
```{r echo = FALSE, cache = TRUE, message=FALSE, results=FALSE}
df.labeled <- read_csv("dflabeledtranslated_edited.csv")
dim(df.labeled)
```

However, for this purpose of predicting feafood_yn based on the dish name, we only need dish 
name (original name and translated name) and class variable seafood_yn. 86,53 percent of 
obsevartion are non seafood dishes, while only 13,46 percent are seafood dishes. 
```{r echo = FALSE, cache = TRUE, results=FALSE}
df.labeled <- df.labeled %>%
  select(name, translatedText, seafood_yn)
## check if there are NA or wrong label format
unique(df.labeled$seafood_yn)
## see proportions
prop.table(table(df.labeled$seafood_yn))
```
## Adding variable.
Our intuition is that there are popular seafood name that will be comprises on most seafood 
dishes. This keywords is something like "dead giveaway" to determine dishes is seafood or not.
We will not use this variable in all of our model, but only in a model where we might want 
to use PCA or SVD to our variable. 

We can see from graph A that most obs that do not contains popular words are indeed not a seafood 
and there are only few of them are seafood. In the other hand, a lot of seafood dishes do not 
contain these popular words, indicating that there are vast amount of vocabulary (fish/ingredient name) 
on a seafood dishes.

We also think that it is unusual for any dish that has a 4 digit number on it's name. Such a 
pattern might be popular on wine or other type of drinks. Because we intend to remove all of 
number in our dish name, we want to reserve is another way, by creating new variable digit4 
(1 if there is 4 digit number in dish name, or 0 if there is no 4 digit number in dish name).

We can see from graph B, most of dishes do not contain 4 digit number. We can also see that 
there are only two dishes that contain 4 digit number are seafood. We can see that this is 
a good distinction measure to determine whether the dish is seafood or not.

```{r echo = FALSE, cache = TRUE}
### adding new variable to df.labeled to improve model performance
popularseafoodwords <- c("oyster", "Oyster", "crab","Crab", "clam", "Clam","lobster","Lobster", 
                         "salmon", "Salmon", "bass", "Bass", "mackerel", "Mackerel","halibut","Halibut",
                         "seafood", "Seafood","turbot","Turbot", "fish","Fish")
popularseafoodwords <- paste(popularseafoodwords,collapse = "|")
df.labeled <- df.labeled %>%
  mutate(popseafood = ifelse(str_detect(translatedText,popularseafoodwords),1,0),
         digit4 = ifelse(str_detect(translatedText,"[:digit:]{4}"),1,0))

ggplot(df.labeled, aes(seafood_yn, popseafood)) + geom_jitter() + 
  theme_bw() + labs(title = "Graph A Seafood dishes on popular words")

ggplot(df.labeled, aes(seafood_yn, digit4)) + geom_jitter() + 
  theme_bw() + labs(title = "Graph B Seafood dishes on whether they contain 4 digit words")
```

## create training and test
We create training and test using 80:20 proportion. However, due to class imbalance on data set, 
we decide to make under sampling training set. This undersampling will benefit us in two ways: 
1. correcting bias problem created by imbalanced class, and 2. Reducing the size of training 
sample, making it faster for some machine learning algorithm such as random forest.

```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
###### create training and test with the same prob #########
set.seed(1234)

#create index of stratified 80:20 split that maintain proportion of label.
index <- caret::createDataPartition(df.labeled$seafood_yn, times = 1,
                                    p = 0.8, list= FALSE) 

# train and test
train <- df.labeled[index,]
test <- df.labeled[-index,]

##verify
prop.table(table(train$seafood_yn))
prop.table(table(test$seafood_yn))

# save(train, file = "train.Rdata")
# save(test, file = "test.Rdata")

###### create training considering class imbalance with undersampling method #########
trainunder <- ovun.sample(seafood_yn~., data = train, method = "under", seed = 1)$data
```


### preprocess training set
Generally we preprocess our training set with following steps:  
1. Make all text lowercase  
2. Remove any punctuation, numbers, symbols, stopwords, and hyphens  
3. Stem the text.  

After all steps completed, we generate make two version of training set: one with all words, 
and one with only noun. We also preprocess undersample training using the same steps. 

Furthermore, due to the dimention of training data, we make "compressed" version of training set. 
We use Singular Value Decomposition to reduce variable to 300 variables. This reduced dimention 
not only will help us increasing processing speed when we run the model, but also tackle multicolleniarity 
problem in datasets, particularly when we want to use Logistic Regression model.

Overall we have four type of training sets:  
1. Training with all vocabulary  
2. Training with only noun  
3. Undersampled training with all vocabulary  
4. Training with SVD  

### preprocess training set with all vocabulary
We first create a corpus from training set. Corpus is a list consist of every words from 
variable translated.We then clean our corpus by following our three cleaning steps, including:
make all text lowecase, removing any unused character, and stem the text, then create document 
frequency matrix. Document frequency matrix is a matrix that consist of every words frequency 
(words counts) for each observation. We then add digit4 variable and class variable (seafood_yn)
to document frequency matrix and save it as data frame.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
#create a corpus
corpus <- corpus(train$translatedText) 

#create document frequency matrix and clean the corpus
dfm.train <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)

##setup feature dataframe with label all words
train.dfm.allword <- data.frame(label=as.factor(train$seafood_yn),
                        digit4 = train$digit4,
                        dfm.train) %>%
  select(-doc_id)

# save(train.dfm.allword, file = "traindfmall.Rdata")
```

### preprocess training set with only noun
We use document frequency matrix from training above then selecting for only noun.
We select noun using udpipe model from udpipe package. We then add digit4 variable 
and class variable to document frequency matrix and save it as data frame.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
## annotate dish name, to create dictionary of noun in training set
dl <- udpipe_download_model(language = "english")
udmodel<- udpipe_load_model(file = dl$file_model)
annotate <- udpipe_annotate(udmodel, train$translatedText)
annotate <- as.data.frame(annotate)
table(annotate$upos)

## selecting only noun
Noun <- annotate %>%
  filter(upos == "NOUN") %>%
  dplyr::select(token)
Noun <- Noun[1:nrow(Noun),]
Noun <- unique(Noun)

# take only Noun from document frequency matrix
dfm.train.Noun <- dfm_select(dfm.train, pattern = Noun)
dim(dfm.train.Noun)

##setup feature dataframe with label noun only
train.dfm.noun <- data.frame(label=as.factor(train$seafood_yn),
                        digit4 = train$digit4,
                        dfm.train.Noun) %>%
  select(-doc_id)

## save the output
# save(train.dfm.noun, file = "traindfmnoun.Rdata")
```

### preprocess training undersampling
We use the same approach to clean and create document frequency matrix. However,
instead of full training dataset, we use training with under sample data frame 
as our corpus.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
## annotate dish name
#create a corpus
corpus <- corpus(trainunder$translatedText) 

#create document frequency matrix and clean the corpus
dfm.train.under <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)

##setup feature dataframe with label
train.dfm.under <- data.frame(label=as.factor(trainunder$seafood_yn),
                        digit4 = trainunder$digit4,
                        dfm.train.under) %>%
  select(-doc_id)

## save the output
# save(train.dfm.under, file = "traindfmunder.Rdata")

```

### preprocess training set with SVD
As noted before we use SVD to create shorter version of training set. We take document 
frequency matrix from full training set then use irlba() function to create dataset with
300 variables.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}

### we start our process from dfm.train (a table that still have all corpus)
dim(dfm.train)

########## Singular value decomposition ##########

### perform SVD to decrease dimentionality  to 300 using package irlba
train.irlba.2 <- irlba(t(dfm.train), nv = 300, maxit = 600)

## save svd value for test data
sigma.inverse.2 <- 1/train.irlba.2$d
u.transpose.2 <- t(train.irlba.2$u)
##setup feature dataframe with label

train.svd <- data.frame(label=as.factor(train$seafood_yn), 
                        popseafood = train$popseafood, 
                        digit4 = train$digit4,
                        train.irlba.2$v)

# save(train.svd,file = "trainingsvd.Rdata")
################# end of SVD ###################################
```

## preprocessing test
In order to make a prediction in our test set, we have to follow the same steps as 
we did for a training set. Furthermore, test set must contain the same variable as 
a training set, so we use training set pattern for test set.

Overall, we have 3 test set:  
1. Test with all vocabulary  
2. Test with only noun  
3. Test with SVD.  

We don't make test set for undersampling because we can use the same test as training
with all words to validate the result for undersampling training.

### preprocess test set all words
We process this test set using the same steps as training set. In addition we 
match variable for this test set with training set with all words.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}

############## choosing only Noun ##############
#create a corpus
corpus <- corpus(test$translatedText) 

#create document frequency matrix with verb
dfm.test <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)

## here we make a document frequency matrix with the same pattern
## as the corresponding training set
dfm.test.allword <- dfm_select(dfm.test, pattern = dfm.train)

##setup feature dataframe with label
test.dfm.allword <- data.frame(label=as.factor(test$seafood_yn),
                        digit4 = test$digit4,
                        dfm.test.allword) %>%
  select(-doc_id)
dim(test.dfm.allword)
```

### preprocess test set Noun only
We process this test set using the same steps as training set. In addition we 
match variable for this test set with training set with nouns only
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
## here we make a document frequency matrix with the same pattern
## as the corresponding training set
dfm.test.Noun <- dfm_select(dfm.test, pattern = dfm.train.Noun)

## setup feature dataframe with label 
test.dfm.Noun <- data.frame(label=as.factor(test$seafood_yn),
                       digit4 = test$digit4, 
                       dfm.test.Noun) %>%
  select(-doc_id)

```

### preprocess test set using all words then convert it to 300 variable using svd
We process this test set using the same steps as training set. In addition we 
match variable for this test set with training set with svd
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
#we already have document frequancy matrix above

### convert test data set to have the samee dimension as training data ##
dfm.test <- dfm_select(dfm.test, pattern = dfm.train)
dfm.test.matrix <- as.matrix(dfm.test)
dim(dfm.test)

########## Singular value decomposition ##########
## we use the same sigma.inverse and u.transpose as we use in training
test.svd <- t(sigma.inverse.2*u.transpose.2 %*% t(as.matrix(dfm.test)))

############### setup feature dataframe with label   ##########
test.svd <- data.frame(label=as.factor(test$seafood_yn), 
                       popseafood = test$popseafood, 
                       digit4 = test$digit4, 
                       test.svd)
dim(test.svd)

# save(test.svd,file = "testsvd.Rdata")
```

# Model performance evaluation
In order to evaluate models, we reate a function to determine best model. We determine 
best model based on accuracy the fuction will return the best accuracy, tuning with the 
best accuracy, and confusion matrix for the model with the best accuracy.
```{r echo = FALSE, cache = TRUE, results=FALSE, warning=FALSE, message=FALSE}
best.accuracy <- function(result, testdf) {
  accuracy <- 1:length(result)
  n.test <- nrow(testdf)
  for (i in seq_along(result)) {
    accuracy[[i]] <- sum(testdf$label == result[[i]] )/n.test 
  }
  CPR <- max(accuracy)
  k <- which.max(accuracy)
  conf.matrix <- confusionMatrix(as.factor(result[[k]]),testdf$label)
  best.model <- list(max_correct_predicted_rate =CPR,
                     best_thershold = k,
                     best_confusion.matric = conf.matrix)
  return(best.model)
}
```

# Running and Validating Machine Learning Models 
## K-nearest neighbour (KNN)
Our first model is K-nearest neighbour (KNN). KNN is a non-parameteric classification 
method where in order to predict a response class, we use the class of k-nearest neighbour 
in the data set. k indicate the number of neighbour we want to use in the model. For example, 
if we choose 3 as k, we look for 3 nearest neighbour of our predicted observation. If two 
or more nearest negihbour is a seafood then we predict seafood and vice versa. The distance
between neighbour is determined using Euclidean Distance.

For this model we only use training with SVD. We cannot unreduced training because there 
is too much similarity the value between observation (most obs will have 0 value), thus 
there will be too many ties.
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
########################### knn #########################
################ using svd version of data ###########
knn.result.svd <- vector(mode = "list",length=5)
tune.knn <- c(5,25,50,100,150) #low k might be overfit models

set.seed(1234)
for (i in seq_along(tune.knn)) {
  knn.result.svd[[i]] <- knn(train.svd[,-1],test.svd[,-1],train.svd$label, k = tune.knn[i])
  
  accuracy[[i]] <- sum(test.svd$label == knn.result.svd[[i]] )/nrow(test.svd)
}

save(knn.result.svd, file = "knn.result.svd.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("knn.result.svd.Rdata")
tune.knn <- c(5,25,50,100,150)
accuracy <- 1:5
for (i in seq_along(tune.knn)) {
  accuracy[[i]] <- sum(test.svd$label == knn.result.svd[[i]] )/nrow(test.svd)
}

## determine the best k
best.accuracy(knn.result.svd,testdf = test.svd)

## graph for number of neighbour (k) vs accuracy
plot(tune.knn, accuracy, lwd= 5)
```
Our best model is using k = 5, with percent 98.05 accuracy. Model has a very high Sensitivity
0.9963 but relatively low Specificity : 0.8857.

## Logistic Regression
Our next model is Logistic Regression. We determine our prediction by measuring probability of
observation being in a class based on coefficient of our variables.

The main benefit of this model is that we can understand what words determine whether a dish
is a seafood or not. However, the main disadvantages is that most words are insignificant and 
since most data frame has a 0 value, most independent variables are dependent with each other.

To tackle this problem we can use svd version of training set. This approach eliminate 
multicollinearity but at the same time deleting main advantages, that is we lose explanability 
of coefficient.
```{r eval=FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
############# using svd version of data #########
logfit.svd <- glm(label ~ ., data = train.svd, family=binomial)

## Took less than a minute to return a model
save(logfit.svd, file = "logfit.svd.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("logfit.svd.Rdata")
##################### predict with test ##################
# predict
logpredict <- predict(logfit.svd, newdata = test.svd,  type = "response")
log.result.svd <- vector(mode = "list",length=100)

## generate list with different threshold
for (i in 1:100) {
  log.result.svd[[i]] <- 1*(logpredict > i/100 )
}

## determine best threshold
best.accuracy(log.result.svd, testdf = test.svd)
```

Other possible approach is to use variable selection. Due to high number of variables 
we choose to include only significant variable (>0.1 alpha) as our final model. In the
code below, we train our train with only.
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
############# using dfm with only Noun version of data #########
logfit.noun <- glm(label ~ ., data = train.dfm.noun, family=binomial)
## there are multicollinerity problem in dataset
coef.table.log.noun <- tidy(logfit.noun)
coef.sig <- coef.table.log.noun %>%
  filter(p.value < 0.1)
term.sig <- paste(coef.sig$term[-1] ,collapse = "+")
logfit.noun <- glm(paste("label~", term.sig, sep = ""), data = train.dfm.noun, family=binomial)
## save model
save(logfit.noun, file = "logfit.noun.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("logfit.noun.Rdata")
##################### predict with test ##################
# predict
logpredict <- predict(logfit.noun, newdata = test.dfm.Noun,  type = "response")

log.result.noun <- vector(mode = "list",length=100)

## generate list with different threshold
for (i in 1:100) {
  log.result.noun[[i]] <- 1*(logpredict > i/100 )
}

## determine best threshold
best.accuracy(log.result.noun, testdf = test.dfm.Noun)
```

As the final approach for logistic regression, we also tried to use undersampling training with
the same approach as training with only noun.
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
############# using dfm with with undersampling #########
logfit.allword <- glm(label ~ ., data = train.dfm.under, family=binomial)
coef.table.log.allword <- tidy(logfit.allword)
coef.sig <- coef.table.log.allword %>%
  filter(p.value < 0.1)
term.sig <- paste(coef.sig$term[-1] ,collapse = "+")


logfit.allword <- glm(paste("label~", term.sig, sep = ""), data = train.dfm.under, family=binomial)
save(logfit.allword, file = "logfitallword.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("logfitallword.Rdata")
##################### predict with test ##################
# predict
logpredict <- predict(logfit.allword, newdata = test.dfm.allword,  type = "response")
log.result.allword <- vector(mode = "list",length=100)

## generate list with different threshold
for (i in 1:100) {
  log.result.allword[[i]] <- 1*(logpredict > i/100 )
}

## determine best threshold
best.accuracy(log.result.allword, testdf = test.dfm.allword)
```
Using Logistic regression, our best model is using training with only noun, with 97.67 
percent accuracy.

## Decision Tree
Decision tree is a very intuitive model. Based on variables in the dataset we will 
create a "branch" that will separate observations whether this is a seafood dish or not.
This separated group of observations became a node (leaves). We then continue to make 
another branch from this node until we can no longer make a new node (that is when our 
accuracy decline when we make new node). In prediction, the class will be determined 
using a mode (whether there is more seafood or non seafood in the node).

Looking at our trees, we can see that all trees create branches using popular seafood name 
i.e oyster, mackerel, bass, etc. Pruned trees version (trees wih smaller number of branches) 
prove to have less accuracy than full grown trees.

Tree 1 : Using train set with noun only
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
### with only noun ######
tree.1 <- tree( label ~ ., train.dfm.noun)
## can we prune? Answer: the biggest tree size has the highest accuracy
## thus it is better not to prune
cv.1 <- cv.tree( tree.1, FUN = prune.misclass )

save(tree.1, file="tree1.Rdata")
save(cv.1, file="cv1.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("tree1.Rdata")
label.predict <-  predict( tree.1, test.dfm.Noun, type="class")
confusionMatrix(label.predict,test.dfm.Noun$label)
```

Tree 2 : Using train set with all words
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
################ all word ####################
tree.2 <- tree( label ~ ., train.dfm.allword)

####### can we prune? Answer: the biggest tree size has the highest accuracy
cv.2 <- cv.tree( tree.2, FUN = prune.misclass )

save(tree.2, file="tree2.Rdata")
save(cv.2, file="cv2.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("tree2.Rdata")
label.predict2 <-  predict( tree.2, test.dfm.allword, type="class" )

confusionMatrix(label.predict2,test.dfm.allword$label)
```

Tree 3 : Using train set with undersampling
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
####################  undersampling training #############
tree.3 <- tree( label ~ ., train.dfm.under)

## can we prune? Answer: the biggest tree size has the highest accuracy
cv.3 <- cv.tree( tree.3, FUN = prune.misclass )
save(tree.3, file="tree3.Rdata")
save(cv.3, file="cv3.Rdata")
```

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("tree3.Rdata")
label.predict3 <-  predict( tree.3, test.dfm.allword, type="class" )
confusionMatrix(label.predict3,test.dfm.allword$label)
# save(tree.3, file="tree3.Rdata")
```

We can tune the model for our training set using 10-cross fold validation to see if
pruning (reducing the number of branches) will reduce error rate. We can see from graph
below that pruning doesn't reducing misclassification rate, thus our model is the best 
decision tree for respective training set.
```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
load("cv1.Rdata")
load("cv2.Rdata")
load("cv3.Rdata")
#Tree 1
plot(cv.1)
title(main = "10-fold CV for Tree 1")

## Tree 2
plot(cv.2)
title(main = "10-fold CV for Tree 2")
## tree 3
plot(cv.3)
title(main = "10-fold CV for Tree 3")
```
Using Decision Tree, our best model is using Training set with all words, with 97.45 percent 
accuracy (Sensitivity : 0.9927  and Specificity : 0.8659).

## Support Vector Machine 
Support Vector Machine (SVM) finds a hyperplane in an N-dimentional space (in case of 
N-number of features) to classify observations. this hyperplane became separator between 
observations, in which opposite side of separator became different class. We can utilize 
different types of hyperplane, including linear (hyperplane is like straight line in 2 
dimentional spaces), polynomial ((hyperplane is like polynomial line in 2 dimentional 
spaces), radial (like a circle in 2 dimentional spaces), and so on. Additionally, we can
also introduce sot in our model. Cost indicate how much we want our model in allowing misclassified
observation in a group. It will determinde how flexible our model is

First, try different cost and different kernel in undersample trainingand see what is 
the best kernel and cost
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
tune.under.svm <- tune(svm, label ~ ., data=train.dfm.under, 
                        ranges=list(cost=10^seq(-2,2), 
                                    kernel=c("linear","polynomial", "sigmoid", "radial")) )
save (tune.under.svm, file = "tunesvm.Rdata")
```

```{r echo=FALSE}
load("tunesvm.Rdata")
summary(tune.under.svm)[[1]]
```

Since the best model is linear kernel with cost = 1, we then can proceed with this model
and use it with different training.
```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
# with under sampling
svm.2 <-  svm( label ~ ., data=train.dfm.under, kernel="linear")

save(svm.2,file = "svmunder.Rdata")

## with noun only
svm <-  svm( label ~ ., data=train.dfm.noun, kernel="linear")
summary(svm)

save(svm,file = "svmundernoun.Rdata")
```
Training with undersampling
```{r echo =FALSE}
load("svmunder.Rdata")
labelpredictsvm2 <-predict(svm.2,test.dfm.allword)
confusionMatrix(labelpredictsvm2,test.dfm.allword$label)
```
Training with all words
```{r echo =FALSE}
load("svmundernoun.Rdata")
labelpredictsvm <-predict(svm,test.dfm.Noun)

confusionMatrix(labelpredictsvm,test.dfm.Noun$label)
```
Using train with noun only gives us very high Sensitivity but much lower Specificity, while
using under sampling, while giving us a little bit lower accuracy gives us a more balanced 
result in both Sensitivity and Specificity. 

## Random Forest
Random forest is a method where we use bagging on decision tree. In Random Ferest, we make n # of 
decision trees, with randomly selected m from p number of variable at the time (where p is number 
of all variable and m<p).  We then make a prediction based on the average probability of all trees
that we make. This model however, lose some degree of interpretability from decision tree.

Due to processing power needed to run random forest, we choose to use run random forest 
only on undersampling training.

```{r eval = FALSE, echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
### tune with different m 
cl <- makeCluster(10)
registerDoSNOW(cl)

tunemtry <- c(20,55,85,250,500)
rfb <- foreach(mtry=c(20,55,85,250,500), .packages='randomForest') %dopar% {
  randomForest(label ~ ., data=train.dfm.under, ntree=500, mtry = mtry)
}

stopCluster(cl)
```

```{r echo =FALSE}
load("rflist.rdata")
tunemtry <- c(20,55,85,250,500)
rf.err <- 1:5
for (i in 1:5) {
  rf.err[i] <- min(rfb[[i]]$err.rate[,1])
}

plot(tunemtry, rf.err)
title(main = "tune vs training error rate")

labelpredict <- vector(mode = "list", length = 5)
for (i in 1:5) {
  rf <- rfb[[i]]
  labelpredictrf <-predict(rf,test.dfm.allword)
  labelpredict[[i]] <- confusionMatrix(labelpredictrf,test.dfm.allword$label)
}

err.rate.test <- 1:5
for (i in 1:5) {
  err.rate.test[i] <- 1- labelpredict[[i]]$overall[1]
}

plot(tunemtry, err.rate.test)
title(main = "tune vs test error rate")
```

Using 500 trees, and 500 words at a time we found our forest 0.9819 in accuracy.
```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
rf.best <- rfb[[5]]
confusion.matrix <- labelpredict[[5]]
## confusion matrix
confusion.matrix

## which words are important when model built trees?
as.data.frame(rf$importance) %>%
  arrange(desc( MeanDecreaseGini)) %>%
  slice(1:20)
```

# Results and Model Selection
We tried Machine learning algorithm in combination of 10 machine learning method and training set. 
Overall we can say that Support Vector Machine and Random Forest gives the best result in term of 
overall accuracy and balanced Sensitivity and Specificity. Random Forest, however, is better at 
predicting seafood dish, something that really important because the number of seafood dish in a 
labeled data is far less than non seafood dishes and we believe overall menu dataset has a similar
distribution.

Additionally, Random Forest gives us major advantages in term of interpretability. While the model 
is not as informative as Decision Tree or logistic regression, we still can see what words are 
mostly a important determinant in predicting seafood or non seafood.

```{r echo = FALSE, cache = TRUE, warning=FALSE, message=FALSE}
#table
result <- rbind(
  data.frame(mode = "KNN", training = "decomposition",best.accuracy(knn.result.svd,testdf = test.svd)$best_confusion.matric$table), ## knn with variable decomposition
  data.frame(mode = "log reg", training = "decomposition", best.accuracy(log.result.svd, testdf = test.svd)$best_confusion.matric$table), ## logistic regressin with variable decomposition
  data.frame(mode = "log reg", training = "noun", best.accuracy(log.result.noun, testdf = test.dfm.Noun)$best_confusion.matric$table), ## logistic regressin with noun only
  data.frame(mode = "log reg", training = "under", best.accuracy(log.result.allword, testdf = test.dfm.allword)$best_confusion.matric$table), ## log reg with all words undersample
  data.frame(mode = "Tree", training = "noun", confusionMatrix(label.predict,test.dfm.Noun$label)$table),  ##decision tree with noun
  data.frame(mode = "Tree",training = "all words", confusionMatrix(label.predict2,test.dfm.allword$label)$table), ##decision tree with all word 
  data.frame(mode = "Tree", training = "under", confusionMatrix(label.predict3,test.dfm.allword$label)$table),  ##decision tree with all word undersample
  data.frame(mode = "svm", training = "noun", confusionMatrix(labelpredictsvm,test.dfm.Noun$label)$table),  ##svm with only noun
  data.frame(mode = "svm", training = "under", confusionMatrix(labelpredictsvm2,test.dfm.allword$label)$table), ##svm with allword undersample
  data.frame(mode = "rand. forest", training = "under", confusion.matrix$table) #random forest with all word undersample
  )

result.table <- result %>%
  group_by(mode, training, Reference) %>%
  mutate(sumreference = ifelse(Reference == 0, sum(Freq[Reference == 0]),
                               sum(Freq[Reference == 1]) )) %>%
  mutate(rate = Freq/sumreference) %>%
  arrange(mode,training, Prediction)

result%>%
  filter(Prediction != Reference) %>%
  ggplot(aes(Reference, Freq, fill= Prediction)) + geom_col() +
  facet_grid(mode~training) + 
  theme_bw() + geom_text(aes(y = 200, label = Freq)) + 
  labs(title = "Number of Misclassified Observation by Model")
```

## Predict all unlabeled data using Random Forest
We will use Random Forest with 500 trees and 500 variable as our model to predict 
unlabeled dataset. We use the same cleaning and preprocessing as we did with test 
dataset.

Due to high # of observations, we create partition with 1000 observations in each 
group. Using foor function, we then predict observation and add them to variable 
seafood_yn.

```{r echo = FALSE, cache = TRUE, eval=FALSE}
unlabeled <- read_csv("dfunlabeledtranslated.csv")
unlabeled <- unlabeled %>%
  mutate(digit4 = ifelse(str_detect(translatedText,"[:digit:]{4}"),1,0))

n <- 1000
nr <- nrow(unlabeled)
unlabeled.list <- split(unlabeled, rep(1:ceiling(nr/n), each=n, length.out=nr))

predict.unlabeled <- function(data, model) {
  ## preprocessing unlabeled
  #create a corpus
  corpus <- corpus(data$translatedText) 
  #create document frequency matrix with verb
  dfm.unlabeled <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)
  
  dfm.unlabeled <- dfm_select(dfm.unlabeled, pattern = dfm.train.under)
  
  df <- data.frame(label=as.factor(0),
                     digit4 = data$digit4,
                     dfm.unlabeled) %>%
    select(-doc_id)

  labelpredict.unlabeled <-predict(model, df)
  return(labelpredict.unlabeled)
}

predict.rf.best <- vector(mode = "list", length = length(unlabeled.list))

## using loop because wa can't do all in one (memory exhaust)
for (i in 1:length(unlabeled.list)) {
  print(i)
  predict.rf.best[[i]] <- data.frame(predict = predict.unlabeled(data = unlabeled.list[[i]], model = rf.best))
}

predict.rf.best.df <- do.call(rbind, predict.rf.best)

unlabeled$seafood_yn <- predict.rf.best.df$predict
unlabeled <- unlabeled %>%
  select(-digit4)
write_csv(unlabeled, file = "unlabeledwithpredicted_fin.csv")
```
# Visualisation
Once we have predicted label for all unlabeled data, we can make visualisation of all dataset.
But first, we need to join all labeled data and unlabeled data that were predicted using random
forest into one dataset.
```{r echo = FALSE, cache = TRUE, message=FALSE, results=FALSE}
################ combine dataset #########
unlabeled <- read_csv("unlabeledwithpredicted_fin.csv")
df.year <- unlabeled %>%
  select(times_appeared, first_appeared, last_appeared, seafood_yn, translatedText)

labeled <- read_csv("dflabeledtranslated_edited.csv")
df.year.2 <- labeled %>%
  select(times_appeared, first_appeared, last_appeared, seafood_yn, translatedText)
df.year <- rbind(df.year,df.year.2)

compiled <- rbind(unlabeled, labeled)
write_csv(compiled, file = "alldatalabeled_fin.csv")
##number of seafood and non seafood
table(df.year$seafood_yn)
##Proportion of seafood and non seaffod
prop.table(table(df.year$seafood_yn))

############# data wrngling for visualisation ##########

df.year <- df.year %>%
  filter(times_appeared > 0) %>%
  filter(!first_appeared %in% c(0,1,2928)) %>%
  filter(!last_appeared %in% c(0,1,2928))
dim(df.year)
## tidying data
data <- vector(mode = "list", length = nrow(df.year))
for (i in seq_along(data)) {
  name.vec <- rep(df.year$translatedText[i], df.year$times_appeared[i])
  label.vec <- rep(df.year$seafood_yn[i], df.year$times_appeared[i])
  year.vec <- if (df.year$times_appeared[i] == 1) {
    c(df.year$first_appeared[i])
  } else if (df.year$times_appeared[i] == 2) {
    c(df.year$first_appeared[i], df.year$last_appeared[i])
    } else if (df.year$times_appeared[i] >2 & df.year$first_appeared[i] == df.year$last_appeared[i]) {
      rep(df.year$first_appeared[i], df.year$times_appeared[i])
    } else {
      c(df.year$first_appeared[i], df.year$last_appeared[i],
        sample(df.year$first_appeared[i]:df.year$last_appeared[i], df.year$times_appeared[i]-2, replace = TRUE))
    } 

data[[i]] <- data.frame (translatedText = name.vec,
                         label = label.vec,
                         year = year.vec)
}

data.1 <- do.call(rbind, data)
data <- data.1 %>%
  mutate(label = as.factor(label))
dim(data)
table(data$label)
prop.table(table(data$label))

seafood <- data %>%
  filter(label == 1)

n.seafood<- data %>%
  filter(label == 0)
```

Example below are graphic we can generate from dataset.

#### Number of dishes throughout years

```{r echo = FALSE, cache = TRUE}
## number of dishes throughout years
data %>%
  ggplot(aes(year, fill = label)) + geom_histogram() + 
  theme_bw() + labs(title = "Dish in the last 200 years", fill = "Seafood")
```

#### Popular seafood processing method
```{r echo = FALSE, cache = TRUE, message=FALSE, error=FALSE}
## annotate seafood
## annotate dish name, to create dictionary of noun in training set
dl <- udpipe_download_model(language = "english")
udmodel<- udpipe_load_model(file = dl$file_model)
annotate <- udpipe_annotate(udmodel, seafood$translatedText)
annotate <- as.data.frame(annotate)
table(annotate$upos)
process <- annotate%>%
  filter(upos == "VERB") %>%
  group_by(lemma) %>%
  tally() %>%
  arrange(desc(n))

corpus.process <- corpus(process$lemma) 

#create document frequency matrix and clean the corpus
dfm.process <- dfm(corpus.process, 
             stem=TRUE, 
             verbose=TRUE)

df.lemma <- data.frame(dfm.process) %>%
  gather(-doc_id, key = key, value = value) %>%
  filter(value != 0)
df.lemma$doc_id <- str_remove_all(df.lemma$doc_id , "text")

df.lemma <- df.lemma %>%
  arrange(parse_number(doc_id))%>%
  filter(!key %in% c("X.","."))
process <- cbind(process, df.lemma)
## provessing words (verb) that are most frequently appears in seafood (with stemming)
top20process <-process %>%
  select(key,n) %>%
  group_by(key) %>%
  summarise(n = sum(n)) %>%
  arrange(desc(n)) %>%
  slice(1:20)

## popular seafood processing verb
ggplot(top20process,aes(reorder(key, -n),n)) + geom_col() + theme_bw() + labs("top 20 processing words in seafood dishes")

corpus.seafood <- corpus(seafood$translatedText)

df.seafood <- dfm(corpus.seafood, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE)

popseafod.peryear <- seafood$year %>%
  unique() %>%
  sort()
process.verb <- top20process$key[1:10]
neg.main.ingred <- c(process.verb,"cocktail")

popprocess.peryear.name <- 1:length(popseafod.peryear)
for ( i in seq_along(popseafod.peryear)) {
  index <- which(seafood$year == popseafod.peryear[[i]])
  df.popular <- df.seafood[index,]
  df.popular <- apply(df.popular,2, sum)
  df.popular <- df.popular[names(df.popular) %in% process.verb]
  popprocess.peryear.name[[i]] <- names(which.max(df.popular))
}

popprocess.peryear <- data.frame(year = popseafod.peryear, 
                                name = popprocess.peryear.name)

## popular processing per decade
popprocess.decade <- popprocess.peryear %>%
  mutate(year = floor(year/10)) %>%
  group_by(year, name) %>%
  tally() %>%
  group_by(year) %>%
  mutate(max = max(n)) %>%
  filter(n == max) %>%
  ungroup() %>%
  mutate(year.start = year*10,
         year.end = year.start + 9) %>%
  select (year.start, year.end, name)

ggplot(data=popprocess.decade) +
  geom_segment(aes(x=year.start, xend=year.end, y=0., yend=0., color=name) , linetype=1, size=4) +
  scale_colour_brewer(palette = "Pastel1") +
  theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major =   element_blank(),
                     axis.title.y=element_blank(),axis.text.y=element_blank(),  axis.ticks.y=element_blank()) +
  theme(aspect.ratio = .2)+
  theme(legend.position="none") + 
  geom_text(aes(x = year.start, y = 0., label=name,angle=45,hjust=0)) +
  labs(title = "Popular seafood processing per decade") + xlab("year")
```

#### Popular seafood per decade
```{r echo = FALSE, cache = TRUE}
popseafod.peryear.name <- 1:length(popseafod.peryear)
for ( i in seq_along(popseafod.peryear)) {
  index <- which(seafood$year == popseafod.peryear[[i]])
  df.popular <- df.seafood[index,]
  df.popular <- apply(df.popular,2, sum)
  df.popular <- df.popular[!names(df.popular) %in% neg.main.ingred]
  popseafod.peryear.name[[i]] <- names(which.max(df.popular))
}

popseafod.peryear <- data.frame(year = popseafod.peryear, 
                                name = popseafod.peryear.name)

## popular seafood per year
# popseafod.peryear

## popular seafood per decade
seafood <- seafood%>%
  mutate(decade = floor(year/10))
popseafod.perdecade <- seafood$decade %>%
  unique() %>%
  sort()

popseafod.perdecade.name <- 1:length(popseafod.perdecade)
for ( i in seq_along(popseafod.perdecade)) {
  index <- which(seafood$decade == popseafod.perdecade[[i]])
  df.popular <- df.seafood[index,]
  df.popular <- apply(df.popular,2, sum)
  df.popular <- df.popular[!names(df.popular) %in% neg.main.ingred]
  popseafod.perdecade.name[[i]] <- names(which.max(df.popular))
}

popseafod.perdecade <- data.frame(year = popseafod.perdecade, 
                                name = popseafod.perdecade.name)
popseafod.perdecade <- popseafod.perdecade %>%
  mutate(year.start = year*10,
         year.end = year.start + 9) %>%
  select (year.start, year.end, name)

popmain.pdecade <- ggplot(data=popseafod.perdecade) +
  theme_bw() + 
  theme(panel.grid.minor = element_blank(), panel.grid.major =   element_blank(),
                     axis.title.y=element_blank(),axis.text.y=element_blank(),
                     axis.ticks.y=element_blank()) +
  theme(aspect.ratio = .2)+
  theme(legend.position="none") + 
  labs(title = "Popular Seafood per decade")

popmain.pdecade +
  geom_segment(aes(x=year.start, xend=year.end, y=0., yend=0., color=name) , linetype=1, size=20) +
  scale_colour_brewer(palette = "Pastel1") +
  geom_text(aes(x = year.start, y = 0., label=name,angle=45,hjust=0)) + xlab("year")

```

#### Plot time series standardise number of dishes
```{r echo=FALSE, cache = TRUE}
data <- data %>%
  group_by(year) %>%
  mutate(n.dish.pyear = length(year))
dish.p.year <- data %>%
  select(year, n.dish.pyear) %>%
  distinct() %>%
  arrange(year)

sf.p.year <- seafood %>%
  group_by(year) %>%
  mutate(n.sf.pyear = length(year)) %>%
  select(year, n.sf.pyear) %>%
  distinct() %>%
  arrange(year)

all.p.year <- dish.p.year %>%
  left_join(sf.p.year) %>%
  mutate( n.sf.norm = n.sf.pyear/n.dish.pyear)

graph1 <- all.p.year%>%
  ggplot(aes(x = year, y = n.sf.norm)) + geom_line() + theme_bw() +
  labs(title = "# of Seafod Dishes Normalized") +
  ylab("proportion of seafood to all dishes")

graph2 <- all.p.year%>%
  gather(ends_with(".pyear"), key = type, value = val) %>%
  ggplot(aes(year,val, fill = type)) + geom_area() + theme_bw() + 
  labs(title = "# of seafood and non seafood", fill = "Seafood/Non Seafood")
graph1
graph2
```


```{r echo=FALSE, cache = TRUE}

# salmon tuna, tilapia, cod
# oyster, lobster, crab, shrimp, clam, turtle, frog
# fried vs non fried
seafood.name.vec <- c("salmon", "tuna", "cod", 
                      "oyster", "lobster", "crab", "shrimp", "clam", "turtl", "frog")
year.unique <- seafood$year %>%
  unique() %>%
  sort()
list.sum <- vector(mode = "list", length = length(year.unique))
for (i in seq_along(list.sum)) {
  year <- year.unique[[i]]
  index <- which(seafood$year == year)
  list.name <- vector(mode = "list", length = length(seafood.name.vec))
  for (j in seq_along(list.name)) {
     name <- seafood.name.vec[j]
     sum <- sum(df.seafood[index,name])
     list.name[[j]] <- data.frame(year = year,
                                 name = name,
                                 num = sum)
  }
  list.sum[[i]] <- do.call(rbind, list.name)
}
df.seafood.name.vec <- do.call(rbind, list.sum)
df.seafood.name.vec.norm <- left_join(df.seafood.name.vec, dish.p.year) %>%
  mutate(num.norm = num/n.dish.pyear)

df.seafood.name.vec.norm %>%
  ggplot(aes(year,num.norm, color= name)) + geom_line() +
  theme_classic()

df.seafood.name.vec.norm <- df.seafood.name.vec.norm %>%
  mutate(decade = floor(year/10))

```

#### Plot changes in popular dishes overtime
```{r echo=FALSE, cache = TRUE}
df.seafood.name.vec.norm%>%
  filter(name %in% c("oyster","crab","salmon","lobster","shrimp")) %>%
  ggplot(aes(year, num.norm, color= name)) + geom_smooth(se=FALSE) + 
  theme_bw() + labs(title = "Changes in Popular Seafood Overtime (Smoothed)") + 
  ylab("Proportion of seafood over all dish")
```

```{r eval= FALSE, echo=FALSE, cache = TRUE}
##sanimate and save as gif
animate.pop <- popmain.pdecade +
  geom_segment(aes(x=year.start, xend=year.end, y=0., yend=0., color=name) , linetype=1, size=20) +
  scale_colour_brewer(palette = "Pastel1") +
  geom_text(aes(x = year.start, y = 0., label=name,hjust=0)) +
  transition_reveal(year.start, keep_last = FALSE) + 
  view_follow(fixed_x = FALSE)
animate.pop <- animate(animate.pop, 300)
anim_save("popdecade", animate.2)

animate.2 <- graph2 + geom_text(aes(y = val, x = year+1, label = type)) +
  transition_reveal(year) +
  view_follow() 
animate.2 <- animate(animate.2, duration = 60)
anim_save("gif2", animate.2)
graph3 <- df.seafood.name.vec.norm%>%
  filter(name %in% c("oyster","crab","salmon","lobster","shrimp")) %>%
  ggplot(aes(year, num.norm, color= name)) + geom_line() + 
  geom_text(aes(y = num.norm, x = year+5,label = name)) +
  theme_bw() + guides(color=FALSE) +
  transition_reveal(year) +
  view_follow() +
  + labs(title = "Changes in Popular Seafood Overtime")
animate.3 <- animate(graph3, duration = 60)
anim_save("popseaffodovertime.gif", animate.3)
```

# Summary

- The model that we use to predict unlabeled dataset is Random forest with ntree= 500 and m=500.   
- The model has 98.21% accuracy, 98.38% sensitivity, and 97.14 specificity on test set.  
- Several pattern that we found including : Oyster was a popular food for almost 100 years! Lobster 
isn’t popular seafood dishes until mid 19th century, and Shrimp steadily increased in popularity.  
- In case of additional dataset need to be predicted using this model I would reccomend this steps
of process
```{r eval= FALSE, echo=FALSE, eval=FALSE }
## load dataset
unlabeled <- read_csv("newdatasetneed")

## mutate dataframe so it consist of the same 
## format as our NYPL dataset, with at least contains
## two variable: translatedText and digit4, 
unlabeled <- unlabeled %>%
  mutate(digit4 = ifelse(str_detect(translatedText,"[:digit:]{4}"),1,0))

## load dfm.train.under
dfm.train.under <- load("traindfmunder.Rdata")

## load model <model is in file called rflist.Rdata, on 5th element
rfb <- load("rflist.rdata")
rf.best <- rfb[[5]]

## function to generate dfm
predict.unlabeled <- function(data, model) {
  ## preprocessing unlabeled
  #create a corpus
  corpus <- corpus(data$translatedText) 
  #create document frequency matrix with verb
  dfm.unlabeled <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)
  
  dfm.unlabeled <- dfm_select(dfm.unlabeled, pattern = dfm.train.under)
  
  df <- data.frame(label=as.factor(0),
                     digit4 = data$digit4,
                     dfm.unlabeled) %>%
    select(-doc_id)

  labelpredict.unlabeled <-predict(model, df)
  return(labelpredict.unlabeled)
}

labeled <- predict.unlabeled(data = unlabeled.list[[i]], model = rf.best))

write_csv(labeled, file = "unlabeledwithpredicted_fin.csv")
```

- Next steps, the labeled dataset can be used to explain other pattern such as fishery collapse, trading.
- All code, report and supporting file are in seafood globalization github repository.

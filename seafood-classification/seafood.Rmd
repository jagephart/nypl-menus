---
title: "seafood"
author: "Alan Nurcahyo"
date: "9/5/2020"
output: pdf_document
---

```{r message=FALSE}
#library used
library(tidyverse)
library(caret)
library(quanteda)
library(doSNOW) #run model to run in each core
library(cld3)
library(googleLanguageR)
library(irlba)
```

# Preprocessing
## Load and review dataset
```{r}
#load dataset
df <- read_csv("/Users/alannurcahyo/Documents/Documents/AU/fall2020/DATA/Seafood_Dishes.csv")
##check label
unique(df$seafood_yn) 

#create labeled dataset
df.labeled <- df %>%
  filter(seafood_yn %in% c(0,1))
prop.table(table(df.labeled$seafood_yn))

#create unlabeled dataset
df.unlabeled <- df %>%
  filter(!seafood_yn %in% c(0,1))

head(df)

```
Evaluate distribution of labeled and non labeled by Year
```{r}
#Histogram of first time the menu appeared
# It appears that the labeled data lack of observation from later year
df %>%
  filter(first_appeared != 0,
         first_appeared != 1,
         first_appeared != 2928) %>%
  mutate( seafoonTF = !is.na(seafood_yn)) %>%
  ggplot(aes(first_appeared, fill = seafoonTF)) + 
  geom_histogram(binwidth = 10)

#Histogram of last time the menu appeared
# It appears that the labeled data has a sufficient range of observation
df %>%
  filter(last_appeared != 0,
         last_appeared != 1,
         last_appeared != 2928) %>%
  mutate( seafoonTF = !is.na(seafood_yn)) %>%
  ggplot(aes(last_appeared, fill = seafoonTF)) + 
  geom_histogram(binwidth = 10)

# comparison between labeled and unlabeled data by first appeared
# It appears that labeled data lack of observation after 1908 
count.first.appeared <- df %>%
  filter(first_appeared != 0,
         first_appeared != 1,
         first_appeared != 2928) %>%
  mutate( seafoodTF = !is.na(seafood_yn)) %>%
  group_by(first_appeared, seafoodTF) %>%
  count() %>%
  spread(seafoodTF, n)

# number of unlabeled observation after 1098 
sum(count.first.appeared$`FALSE`[count.first.appeared$first_appeared>1907])

# number of labeled observation after 1098 
sum(count.first.appeared$`TRUE`[count.first.appeared$first_appeared>1907], na.rm = TRUE)

# let's take one percent of oberservation after 1908 to be labeled and round it
# per year we need following observation
n_new_sample <- count.first.appeared %>%
  mutate(n_sample = round(`FALSE`/100,0)) %>%
  select(first_appeared,n_sample) %>%
  filter(first_appeared >1907,
         n_sample >0)

## we take n number of observation from unlabeled dataset by following the number we need on n_new_sample$n_sample
new_sample <- vector(mode = "list", length = nrow(n_new_sample))
for (i in seq_along(new_sample)) {
  new_sample[[i]] <- df.unlabeled %>%
    filter(first_appeared == n_new_sample$first_appeared[[i]]) %>%
    sample_n(n_new_sample$n_sample[[i]])
}
new_sample <- do.call(rbind, new_sample)

# write it to csv
write_csv(new_sample,"new_sample.csv")

```

Translate
```{r}
############### detect langauage use cld3 #################### 
df.labeled.cld3 <- df.labeled%>%
  mutate(name = str_to_lower(name),
         lang = cld3::detect_language(name))

###################### use google API #########################
## the output file is saved in .csv because it is costly and time consuming to run it everytime
# gl_auth("seafood-translation-f329aa685c7f.json")
# df.name.translate <- vector(mode = "list", length = nrow(df.labeled))
# 
# for (i in seq_along(df.name.translate)) {
#      df.name.translate[[i]] <- gl_translate(df.labeled$name[i], target = "en")
# }
# 
# df.name.translate.bind <- do.call(rbind, df.name.translate)
# prop.table(table(df.name.translate.bind$detectedSourceLanguage))
# 
# write.csv(df.name.translate.bind,"NameTranslated.csv")
df.name.translate.bind <- read_csv("NameTranslated.csv")

##use translated as our dataset
df.labeled <- cbind(df.labeled, df.name.translate.bind)
df.labeled <- df.labeled %>%
  dplyr::select(-text , -X1, -description)
head(df.labeled)


## Comparation between cld3 and GoogleAPI  -- googleAPI is outperform cld3 in language detection

df.name.translate.bind %>%
  group_by(detectedSourceLanguage) %>%
  tally() %>%
  arrange(desc(n)) %>%
  mutate(prop = n/nrow(df.name.translate.bind)) %>%
  slice(1:5) %>%
  ggplot(aes(detectedSourceLanguage,prop)) + geom_col() +
  theme_bw() + labs(title = "top 5 language by google")

df.labeled.cld3 %>%
  group_by(lang) %>%
  tally() %>%
  arrange(desc(n)) %>%
  mutate(prop = n/nrow(df.name.translate.bind)) %>%
  slice(1:5) %>%
  ggplot(aes(lang,prop)) + geom_col() +
  theme_bw() + labs(title = "top 5 language by cld3")

head(df.labeled)
```

# create training and test

```{r}
set.seed(1234)

#create index of stratified 70:30 split that maintain proportion of label.
index <- caret::createDataPartition(df.labeled$seafood_yn, times = 1,
                                    p = 0.7, list= FALSE) 

# train and test
train <- df.labeled[index,]
test <- df.labeled[-index,]

##verify
prop.table(table(train$seafood_yn))
prop.table(table(test$seafood_yn))

```


## preprocess training set
```{r}
library(udpipe)
dl <- udpipe_download_model(language = "english")
udmodel<- udpipe_load_model(file = dl$file_model)
annotate <- udpipe_annotate(udmodel, train$translatedText)
annotate <- as.data.frame(annotate)
table(annotate$upos)
all.verb.train <- annotate %>%
  filter(upos == "VERB") %>%
  dplyr::select(token)
all.verb.train <- all.verb.train[1:nrow(all.verb.train),]
all.verb.train <- unique(all.verb.train)
```

```{r}
#create a corpus
corpus <- corpus(train$translatedText) 

#create document frequency matrix with verb
dfm.train <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)

view(dfm.train[1:20,1:100])
dim(dfm.train)

#create document frequency matrix without verb
dfm.train <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove = c(all.verb.train, stopwords('english', source = "snowball")),
             stem=TRUE, 
             verbose=TRUE)

view(dfm.train[1:20,1:100])
dim(dfm.train)

############## make TF-IDF version of data ##################
## make tf function
term.frequency <- function(row){
  row/sum(row)
}

## make function to calculate IDF
inverse.doc.freq <- function(col) {
  corpus.size <- length(col)
  doc.count <- length(which(col>0))
  log10(corpus.size/doc.count)
}

## make function to calculate tf/idf

tf.idf <- function(tf,idf) {
  tf*idf
}

## make tf matrix transformation 
dfm.train.tf <- apply(dfm.train, 1, term.frequency)
dim(dfm.train)

## make idf . NOTe: This IDF will be used again later in test dataset
dfm.train.idf <- apply(dfm.train, 2, inverse.doc.freq)

## make tf-idf matrix 
dfm.train.tfidf <- apply(dfm.train.tf, 2, tf.idf, idf = dfm.train.idf)
dim(dfm.train.tfidf)

## transpose t-idf matrix
dfm.train.tfidf <- t(dfm.train.tfidf)
dim(dfm.train.tfidf)
view(dfm.train.tfidf[1:20,1:100])

## check incomplete cases -- it is possible that with our preprocessing some dish 
## have name that being removed
incomplete.cases <- which(!complete.cases(dfm.train.tfidf))
train$translatedText[incomplete.cases]

## fix it
dfm.train.tfidf[incomplete.cases,] <- rep(0.0, ncol(dfm.train.tfidf))

################ end of tf-idf ##################


########## Singular value decomposition ##########

## record start time
start.time <- Sys.time()

### perform SVD to decrease dimentionality  to 300 using package irlba
train.irlba <- irlba(t(dfm.train.tfidf), nv = 300, maxit = 600)

## total time ~12 minutes
total.time <- Sys.time() - start.time 


## save svd value for test data
sigma.inverse <- 1/train.irlba$d
u.transpose <- t(train.irlba$u)

##setup feature dataframe with label
train.svd <- data.frame(label=as.factor(train$seafood_yn), train.irlba$v)
dim(train.svd)

save(train.svd,file = "trainingsvd.Rdata")
load("trainingsvd.Rdata")

################# end of SVD ###################################
```

## preprocessing test
```{r}
#create a corpus
corpus <- corpus(test$translatedText) 


#create document frequency matrix in a go
dfm.test <- dfm(corpus, 
             tolower=TRUE,  
             remove_punct =TRUE, 
             remove_numbers=TRUE,
             remove_symbols = TRUE,
             remove_hyphens = TRUE,
             remove=stopwords('english', source = "snowball"), 
             stem=TRUE, 
             verbose=TRUE)

view(dfm.test[1:20,1:100])

### convert test data set to have the samee dimension as training data ##
dfm.test <- dfm_select(dfm.test, pattern = dfm.train)
dfm.test.matrix <- as.matrix(dfm.test)
dim(dfm.test)

############## make TF-IDF version of data ##################

## make tf matrix transformation 
dfm.test.tf <- apply(dfm.test.matrix, 1, term.frequency)


## make tf-idf matrix using idf from training data, 
## because we expect that any new document that comes in the future has to
## correspondent with our main corpus (training data)
dfm.test.tfidf <- apply(dfm.test.tf, 2, tf.idf, idf = dfm.train.idf)
dim(dfm.test.tfidf)

## transpose t-idf matrix
dfm.test.tfidf <- t(dfm.test.tfidf)
dim(dfm.test.tfidf)
view(dfm.train.tfidf[1:20,1:100])

## check incomplete cases -- it is possible that with our preprocessing some dish 
## have name that being removed
incomplete.cases <- which(!complete.cases(dfm.test.tfidf))

## fix it
dfm.test.tfidf[incomplete.cases,] <- rep(0.0, ncol(dfm.test.tfidf))

################ end of tf-idf ##################


########## Singular value decomposition ##########

test.svd <- t(sigma.inverse*u.transpose %*% t(dfm.test.tfidf))

##setup feature dataframe with label
test.svd <- data.frame(label=as.factor(test$seafood_yn), test.svd)
dim(test.svd)

save(test.svd,file = "testsvd.Rdata")

################# end of SVD ###################################
```

## use KNN (simplest classification I know, to boost processing time)

```{r}
set.seed(1234)
# use caret package to make stratified 10-fold cross validation repeated

cv.folds <- createMultiFolds(train.svd$label, k = 10, times = 2)
cv.control <- trainControl(method = "repeatedcv", number = 10,
                           repeats = 2, index = cv.folds)

# time the code execution
start.time <- Sys.time()

knnFit <- train(label ~ ., data = train.svd, 
                method = "knn", 
                trControl = cv.control, 
                preProcess = c("center","scale"), 
                tuneLength = 10)

total.time <- Sys.time() - start.time


## Took about 3 hours to train the model
total.time
## save(knnFit,file = "knnFit.Rdata")
load("knnFit.Rdata")
knnFit
plot(knnFit)

##################### predict with test ##################
# time the code execution
start.time <- Sys.time()
# predict
knnpredict <- predict(knnFit, newdata = test.svd )

total.time.predict <- Sys.time() - start.time

confusionMatrix(knnpredict, test.svd$label )

test.result <- data.frame( predicted = knnpredict, test)
test.result %>%
  select(predicted, name, seafood_yn) %>%
  filter (!predicted == seafood_yn,
          seafood_yn == 1)

## the result has a relatively high accuracy -96 percent-, but low specitifity(positive class is0)
## probably the model could perform better if somehow we can help the machine to understand 
## more about context, that oyster and lobster is a seafood. or use model that will fit data better
## for example decision tree/ random forest

# Confusion Matrix and Statistics
# 
#           Reference
# Prediction    0    1
#          0 7426  173
#          1  118  885
#                                           
#                Accuracy : 0.9662          
#                  95% CI : (0.9621, 0.9699)
#     No Information Rate : 0.877           
#     P-Value [Acc > NIR] : < 2.2e-16       
#                                           
#                   Kappa : 0.8396          
#                                           
#  Mcnemar's Test P-Value : 0.001548        
#                                           
#             Sensitivity : 0.9844          
#             Specificity : 0.8365          
#          Pos Pred Value : 0.9772          
#          Neg Pred Value : 0.8824          
#              Prevalence : 0.8770          
#          Detection Rate : 0.8633          
#    Detection Prevalence : 0.8834          
#       Balanced Accuracy : 0.9104          
#                                           
#        'Positive' Class : 0   

## the result has a slightly less accuracy -96 percent-, but higher specitifity(positive class is0)

```


## use logistic regression (less memory demand than random forest, to boost processing time)

```{r}
set.seed(1234)
# use caret package to make stratified 10-fold cross validation repeated

# time the code execution
start.time <- Sys.time()

logFit <- train(label ~ ., data = train.svd, 
                method = "glm", 
                family=binomial(),
                trControl = cv.control, 
                tuneLength = 10)

total.time.train.log <- Sys.time() - start.time


## Took about 11 min to train the model
total.time
save(logFit,file = "logFit.Rdata")


##################### predict with test ##################
# time the code execution
start.time <- Sys.time()
# predict
logpredict <- predict(logFit, newdata = test.svd )

total.time.predict.log <- Sys.time() - start.time

confusionMatrix(logpredict, test.svd$label )

# Confusion Matrix and Statistics
# 
#           Reference
# Prediction    0    1
#          0 7300  156
#          1  244  902
#                                           
#                Accuracy : 0.9535          
#                  95% CI : (0.9488, 0.9579)
#     No Information Rate : 0.877           
#     P-Value [Acc > NIR] : < 2.2e-16       
#                                           
#                   Kappa : 0.7919          
#                                           
#  Mcnemar's Test P-Value : 1.361e-05       
#                                           
#             Sensitivity : 0.9677          
#             Specificity : 0.8526          
#          Pos Pred Value : 0.9791          
#          Neg Pred Value : 0.7871          
#              Prevalence : 0.8770          
#          Detection Rate : 0.8486          
#    Detection Prevalence : 0.8668          
#       Balanced Accuracy : 0.9101          
#                                           
#        'Positive' Class : 0

```

# try to use original high dimention data with log regression
```{r}
train.noverb <- data.frame(label = as.factor(train$seafood_yn), dfm.train)
train.noverb <- train.noverb %>%
  dplyr::select(-document)

test.noverb <- data.frame(label = as.factor(test$seafood_yn), dfm.test)
test.noverb <- test.noverb %>%
  dplyr::select(-document)

set.seed(1234)
# use caret package to make stratified 10-fold cross validation repeated
# use caret package to make stratified 10-fold cross validation repeated

cv.folds <- createMultiFolds(train.noverb$label, k = 10, times = 2)
cv.control <- trainControl(method = "repeatedcv", number = 10,
                           repeats = 2, index = cv.folds)

# time the code execution
start.time <- Sys.time()

noverb.logFit <- train(label ~ ., data = train.noverb, 
                method = "glm", 
                family=binomial(),
                trControl = cv.control, 
                tuneLength = 10)

total.time.train.log.noverb <- Sys.time() - start.time


## Took o train the model
total.time
save(allvar.logFit,file = "allvar.logFit.Rdata")


##################### predict with test ##################
# time the code execution
start.time <- Sys.time()
# predict
allvar.logFit <- predict(allvar.logFit, newdata = test.tfidf )

total.time.predict.log.allvar <- Sys.time() - start.time

confusionMatrix(allvar.logFit, test.tfidf$label )
```

# make models use random forest 
## use R default setting - Error: protect(): protection stack overflow 
## - try to tweak default R setting: Error: vector memory exhausted (limit reached?)
## solution to try: use machine with bigger memory
```{r}
# set.seed(1234)
# 
# cv.folds <- createMultiFolds(train$seafood_yn, k = 10, times = 1)
# cv.control <- trainControl(method = "repeatedcv", number = 10,
#                            repeats = 1, index = cv.folds)
# 
# cl <- DoSNOW::makeCluster(20)
# registerDoSNOW(cl)
# 
# # time the code execution
# start.time <- Sys.time()
# 
# # build decision tree - rpart
# rpart.cv.1 <- train(label~.,data = train.svd, 
#                     method = "rf",
#                     trcontrol = cv.control,
#                     tuneLength = 10)
# 
# total.time <- Sys.time() - start.time
# 
# DoSNOW::stopCluster(cl)
load("trainingrf.Rdata")
rf.cv.1
# rfpredict <- predict(rf.cv.1, newdata = test.svd)
load("rfpredict.rdata")
confusionMatrix(rfpredict, test.svd$label)
```
